{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_Tuning_and_Model_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dphi-official/Machine_Learning_Bootcamp/blob/master/Hyperparameter_Tuning_and_Model_Evaluation/Hyperparameter_Tuning_and_Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK6jjKYQbGgt"
      },
      "source": [
        "# **Agenda**\n",
        "*  Objective\n",
        "*  About the Dataset\n",
        "*  Loading Libraries\n",
        "*  Loading Data\n",
        "*  Basic EDA\n",
        "*  Basic Pre-processing\n",
        "*  Separating Input and Output Vairables\n",
        "*  Splitting data into Train and Validation set\n",
        "*  Building Model: RandomForestClassifer\n",
        "*  Improve Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlQLegAXd8m9"
      },
      "source": [
        "## **Objective**\n",
        "The objective is to know if a patient has liver disease or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCw_dZjycIHU"
      },
      "source": [
        "## About the Dataset\n",
        "\n",
        "**Context**\n",
        "\n",
        "Patients with Liver disease have been continuously increasing because of excessive consumption of alcohol, inhale of harmful gases, intake of contaminated food, pickles and drugs. This dataset was used to evaluate prediction algorithms in an effort to reduce burden on doctors.\n",
        "\n",
        "**Content**\n",
        "\n",
        "This data set contains 416 liver patient records and 167 non liver patient records collected from North East of Andhra Pradesh, India. The \"Dataset\" column is a class label used to divide groups into liver patient (liver disease) or not (no disease). This data set contains 441 male patient records and 142 female patient records.\n",
        "\n",
        "Any patient whose age exceeded 89 is listed as being of age \"90\".\n",
        "\n",
        "**Columns:**\n",
        "\n",
        "*  Age of the patient\n",
        "*  Gender of the patient\n",
        "*  Total Bilirubin\n",
        "*  Direct Bilirubin\n",
        "*  Alkaline Phosphotase\n",
        "*  Alamine Aminotransferase\n",
        "*  Aspartate Aminotransferase\n",
        "*  Total Protiens\n",
        "*  Albumin\n",
        "*  Albumin and Globulin Ratio\n",
        "*  liver_disease: field used to split the data into two sets (patient with liver disease, or no disease). 1 --> Have liver disease, 0 --> No liver disease\n",
        "\n",
        "\n",
        "The dataset is available at UCI Machine Learning Repository, Kaggle and DPhi official GitHub page.\n",
        "\n",
        "**Dataset Link:** https://github.com/dphi-official/Datasets/blob/master/liver_patient.csv\n",
        "\n",
        "**GitHub raw data link:** https://raw.githubusercontent.com/dphi-official/Datasets/master/liver_patient.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nruxxIg1ekce"
      },
      "source": [
        "## **Loading Libraries**\n",
        "All Python capabilities are not loaded to our working environment by default (even they are already installed in your system). So, we import each and every library that we want to use.\n",
        "\n",
        "In data science, numpy and pandas are most commonly used libraries. Numpy is required for calculations like means, medians, square roots, etc. Pandas is used for data processing and data frames. Matplotlib is used for data visualization. We chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd, matplotlib.pyplot as plt).\n",
        "\n",
        "**You can load/import all the libraries at one place that you think might be required or can import whenever needed.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz29p2o9Z-5w"
      },
      "source": [
        "import pandas as pd       # to read data\n",
        "import numpy as np        # to perform calculations \n",
        "import matplotlib.pyplot as plt # to visualise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMeZaoK8fQ2A"
      },
      "source": [
        "## **Loading the Data**\n",
        "Pandas module is used for reading data of different formats. However, we have used here read_csv() function to read the data as our data is in comma separated format (CSV)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UVOeRONfQQe"
      },
      "source": [
        "# In read_csv() function, we have passed the location to where the file is located at dphi official github page\n",
        "liver_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/liver_patient.csv\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yy0BNpqivDz"
      },
      "source": [
        "## **Basis Exploratory Data Analysis (EDA)**\n",
        "Let's check how our data looks. This can be done using head() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfRS7pU2ikFt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "8e43382c-634e-43c1-d3d4-c4af5974613f"
      },
      "source": [
        "liver_data.head()       # head() returns you the first five rows of the data. Similarly, you can use tail() to get last 5 rows of data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Total_Bilirubin</th>\n",
              "      <th>Direct_Bilirubin</th>\n",
              "      <th>Alkaline_Phosphotase</th>\n",
              "      <th>Alamine_Aminotransferase</th>\n",
              "      <th>Aspartate_Aminotransferase</th>\n",
              "      <th>Total_Protiens</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Albumin_and_Globulin_Ratio</th>\n",
              "      <th>liver_disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>187</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>Male</td>\n",
              "      <td>10.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>699</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62</td>\n",
              "      <td>Male</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>490</td>\n",
              "      <td>60</td>\n",
              "      <td>68</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>182</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>Male</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>195</td>\n",
              "      <td>27</td>\n",
              "      <td>59</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Gender  ...  Albumin_and_Globulin_Ratio  liver_disease\n",
              "0   65  Female  ...                        0.90              1\n",
              "1   62    Male  ...                        0.74              1\n",
              "2   62    Male  ...                        0.89              1\n",
              "3   58    Male  ...                        1.00              1\n",
              "4   72    Male  ...                        0.40              1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuuu0gJgjZTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2299dba5-1f00-4f8c-8f37-fa8d19574e2f"
      },
      "source": [
        "# Columns/Attributes\n",
        "liver_data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'Gender', 'Total_Bilirubin', 'Direct_Bilirubin',\n",
              "       'Alkaline_Phosphotase', 'Alamine_Aminotransferase',\n",
              "       'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin',\n",
              "       'Albumin_and_Globulin_Ratio', 'liver_disease'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e928TJ8Gjlmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb473b05-4416-467a-bb03-fc86dcceaa2f"
      },
      "source": [
        "# concise summary about dataset\n",
        "liver_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 583 entries, 0 to 582\n",
            "Data columns (total 11 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   Age                         583 non-null    int64  \n",
            " 1   Gender                      583 non-null    object \n",
            " 2   Total_Bilirubin             583 non-null    float64\n",
            " 3   Direct_Bilirubin            583 non-null    float64\n",
            " 4   Alkaline_Phosphotase        583 non-null    int64  \n",
            " 5   Alamine_Aminotransferase    583 non-null    int64  \n",
            " 6   Aspartate_Aminotransferase  583 non-null    int64  \n",
            " 7   Total_Protiens              583 non-null    float64\n",
            " 8   Albumin                     583 non-null    float64\n",
            " 9   Albumin_and_Globulin_Ratio  579 non-null    float64\n",
            " 10  liver_disease               583 non-null    int64  \n",
            "dtypes: float64(5), int64(5), object(1)\n",
            "memory usage: 50.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFb7W5U3jyAD"
      },
      "source": [
        "*  There are 583 non-null values in each of the columns except **Albumin_and_Globulin_Ratio**. This column has only 579 non-null values i.e. there are 4 missing/null values.\n",
        "\n",
        "*  All the columns are numerical, i.e. the data types are either int or float except **Gender**. Gender has all the values as object either 'Male' or 'Female'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dve9DrOJkrVZ"
      },
      "source": [
        "Taking a look at the count of patient who has liver disease and that who don't have liver disease. This can be achieved by a method called 'value_counts()'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAl1kKoAjs0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890d5b62-88f1-45f8-9426-77f036f04fdd"
      },
      "source": [
        "liver_data.liver_disease.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    416\n",
              "0    167\n",
              "Name: liver_disease, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnCUwjJrbf09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a6405b-2dc7-45d5-ae05-5d298d9e0efd"
      },
      "source": [
        "liver_data.Gender.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Male      441\n",
              "Female    142\n",
              "Name: Gender, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjcu4Jhbk9dG"
      },
      "source": [
        "Out of 583 patients, 416 have liver disease while 167 don't."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGYaOj4sqAYP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "537804ad-13a3-4544-a27e-21f69f29b969"
      },
      "source": [
        "# Taking a look at missing values in column Albumin_and_Globulin_Ratio\n",
        "liver_data[liver_data['Albumin_and_Globulin_Ratio'].isnull()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Total_Bilirubin</th>\n",
              "      <th>Direct_Bilirubin</th>\n",
              "      <th>Alkaline_Phosphotase</th>\n",
              "      <th>Alamine_Aminotransferase</th>\n",
              "      <th>Aspartate_Aminotransferase</th>\n",
              "      <th>Total_Protiens</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Albumin_and_Globulin_Ratio</th>\n",
              "      <th>liver_disease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>45</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.3</td>\n",
              "      <td>189</td>\n",
              "      <td>23</td>\n",
              "      <td>33</td>\n",
              "      <td>6.6</td>\n",
              "      <td>3.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>51</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>230</td>\n",
              "      <td>24</td>\n",
              "      <td>46</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>35</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>180</td>\n",
              "      <td>12</td>\n",
              "      <td>15</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>27</td>\n",
              "      <td>Male</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.6</td>\n",
              "      <td>106</td>\n",
              "      <td>25</td>\n",
              "      <td>54</td>\n",
              "      <td>8.5</td>\n",
              "      <td>4.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Age  Gender  ...  Albumin_and_Globulin_Ratio  liver_disease\n",
              "209   45  Female  ...                         NaN              1\n",
              "241   51    Male  ...                         NaN              1\n",
              "253   35  Female  ...                         NaN              0\n",
              "312   27    Male  ...                         NaN              0\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyX5xI_Rqdmq"
      },
      "source": [
        "Since the column **Albumin_and_Globulin_Ratio** has continuous values, we can fill the missing values here with the mean value of this particular column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5dCckW5qudc"
      },
      "source": [
        "# filling the missing values\n",
        "liver_data.Albumin_and_Globulin_Ratio.fillna(liver_data['Albumin_and_Globulin_Ratio'].mean(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-i7F6UvlGYd"
      },
      "source": [
        "## **Basic Pre-processing**\n",
        "\n",
        "**Converting the categorical values of Gender column to Numerical**\n",
        "\n",
        "*Why do we need to do this?*\n",
        "\n",
        "All the machine learning models only accepts numerical values. They work only on numbers. If you pass any categorical value in any machine learning model, it will throw an error. Don't believe it. Well as a data scientist, we should always do experiments. Try giving the categorical value to any model and observe the result.\n",
        "\n",
        "We can achieve this by one hot encoding.\n",
        "\n",
        "In this strategy, each category value is converted into a new column and assigned a 1 or 0 (notation for true/false) value to the column. In Python there is a class 'OneHotEncoder' in 'sklearn.preprocessing' to do this task, but here we will use pandas function 'get_dummies()'. This get_dummies() does the same work as done by 'OneHotEncoder' form sklearn.preprocessing.\n",
        "\n",
        "![alt text](https://dphi.tech/blog/wp-content/uploads/2020/06/ohe.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5AXwup2k6k8"
      },
      "source": [
        "liver_data = pd.get_dummies(liver_data, columns=['Gender'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_oRYGj1s4wt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "046540e6-8313-4638-e6a4-b0e29484d08e"
      },
      "source": [
        "liver_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Total_Bilirubin</th>\n",
              "      <th>Direct_Bilirubin</th>\n",
              "      <th>Alkaline_Phosphotase</th>\n",
              "      <th>Alamine_Aminotransferase</th>\n",
              "      <th>Aspartate_Aminotransferase</th>\n",
              "      <th>Total_Protiens</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Albumin_and_Globulin_Ratio</th>\n",
              "      <th>liver_disease</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.1</td>\n",
              "      <td>187</td>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>10.9</td>\n",
              "      <td>5.5</td>\n",
              "      <td>699</td>\n",
              "      <td>64</td>\n",
              "      <td>100</td>\n",
              "      <td>7.5</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62</td>\n",
              "      <td>7.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>490</td>\n",
              "      <td>60</td>\n",
              "      <td>68</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>182</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.0</td>\n",
              "      <td>195</td>\n",
              "      <td>27</td>\n",
              "      <td>59</td>\n",
              "      <td>7.3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Total_Bilirubin  ...  Gender_Female  Gender_Male\n",
              "0   65              0.7  ...              1            0\n",
              "1   62             10.9  ...              0            1\n",
              "2   62              7.3  ...              0            1\n",
              "3   58              1.0  ...              0            1\n",
              "4   72              3.9  ...              0            1\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQjXLTpbtZ3F"
      },
      "source": [
        "## **Separating Input Features and Output Features**\n",
        "Before building any machine learning model, we always separate the input variables and output variables. Input variables are those quantities whose values are changed naturally in an experiment, whereas output variable is the one whose values are dependent on the input variables. So, input variables are also known as independent variables as its values are not dependent on any other quantity, and output variable/s are also known as dependent variables as its values are dependent on other variable i.e. input variables. Like here in this data, we are trying to predict the price if a patient has liver disease or not i.e. 'Dataset' variable. Sot 'Dataset' variable is our dependent variable.\n",
        "\n",
        "By convention input variables are represented with 'X' and output variables are represented with 'y'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQRKPoFas7rz"
      },
      "source": [
        "X = liver_data.drop('liver_disease', axis = 1)              # Input Variables/features\n",
        "y = liver_data.liver_disease                                # output variables/features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DmOPHJJuBYh"
      },
      "source": [
        "## **Splitting the data**\n",
        "We want to check the performance of the model that we built. For this purpose, we always split (both input and output data) the given data into training set which will be used to train the model, and test set which will be used to check how accurately the model is predicting outcomes.\n",
        "\n",
        "For this purpose we have a class called 'train_test_split' in the 'sklearn.model_selection' module.\n",
        "\n",
        "We split 80% of the data to the training set while 20% of the data to test set using below code. The test_size variable is where we actually specify the proportion of the test set.\n",
        "\n",
        "By passing our X and y variables into the train_test_split method, we are able to capture the splits in data by assigning 4 variables to the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ3lAAKtt8dM"
      },
      "source": [
        "# import train_test_split\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "# Assign variables to capture train test split output\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101,stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5v6s0S6K1vv"
      },
      "source": [
        "X_train: independent/input feature data for training the model\n",
        "\n",
        "y_train: dependent/output feature data for training the model\n",
        "\n",
        " X_test: independent/input feature data for testing the model; will be used to predict the output values\n",
        "\n",
        "y_test: original dependent/output values of X_test; We will compare this values with our predicted values to check the performance of our built model.\n",
        " \n",
        "test_size = 0.20: 20% of the data will go for test set and 70% of the data will go for train set\n",
        "\n",
        "random_state = 42: this will fix the split i.e. there will be same split for each time you run the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90EzqLvbfXPX"
      },
      "source": [
        "*Baseline model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwclmCsYfWAY",
        "outputId": "8829d3a3-7a3c-46e9-b6b5-e6ebbccf92d0"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "rfc = RandomForestClassifier()\r\n",
        "rfc.fit(X_train,y_train)\r\n",
        "y_pred = rfc.predict(X_test)\r\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.24      0.32        34\n",
            "           1       0.74      0.90      0.82        83\n",
            "\n",
            "    accuracy                           0.71       117\n",
            "   macro avg       0.62      0.57      0.57       117\n",
            "weighted avg       0.67      0.71      0.67       117\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "41xaGD8L-zSn",
        "outputId": "da15341d-d4c3-4acd-f276-f91f241d0127"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "plot_confusion_matrix(rfc,X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f989feda390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0EAeOtPeWSn"
      },
      "source": [
        "**Handling Class Imbalance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x31FU5wAeiPU",
        "outputId": "1fbb7d0a-6018-4060-ff60-bd8a07145d10"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\r\n",
        "from collections import Counter\r\n",
        "ros = RandomOverSampler(random_state=42)\r\n",
        "\r\n",
        "# fit predictor and target variable\r\n",
        "x_ros, y_ros = ros.fit_resample(X, y)\r\n",
        "print('Original dataset shape', Counter(y))\r\n",
        "print('Resample dataset shape', Counter(y_ros))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original dataset shape Counter({1: 416, 0: 167})\n",
            "Resample dataset shape Counter({1: 416, 0: 416})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHsSxUVVgjXN"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x_ros, y_ros, test_size=0.2, random_state=42, stratify=y_ros)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX1pSonVsuaq"
      },
      "source": [
        "## **Building Model: Random Forest Classifier**\n",
        "First, we need to import our model - Random Forest Classifier (again, using the sklearn library).\n",
        "\n",
        "Then we would feed the model both with the data (X_train) and the answers for that data (y_train)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpt8JjJ1r0N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96f658f8-0d29-4e36-9401-7d900fc2e538"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier   # import the model\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train, y_train)           # Training the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH3BblL2bjfZ"
      },
      "source": [
        "### **Evaluate the model**\n",
        "Now we have a model. Let's evaulate it with using the accuracy_score function. This output of the function is the number of right answers (i.e. the patient who has actually the liver disease were predicted by the model as having liver disease)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUtEJa86sCNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa2ca9a-6635-40ca-b92b-6052263d9dfc"
      },
      "source": [
        "print(classification_report(y_test,rfc.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.98      0.88        84\n",
            "           1       0.97      0.75      0.84        83\n",
            "\n",
            "    accuracy                           0.86       167\n",
            "   macro avg       0.88      0.86      0.86       167\n",
            "weighted avg       0.88      0.86      0.86       167\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sdDuPdatuip"
      },
      "source": [
        "The large difference between the training score and the test score suggests that our model overfits. That is, instead of learning general rules that can be applied on unseen data, it does something that is more similar to memorize the training data. So our model performs really well on the training data (100% accuracy) but not remotely as well on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNp6ggJ-mRzj"
      },
      "source": [
        "**Using Boosting model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs-Upa6-mbjH",
        "outputId": "b50a02a2-c9e2-4eeb-f090-14d0d1a479bc"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "\r\n",
        "model = GradientBoostingClassifier()\r\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kMTXF9Gm6Rt",
        "outputId": "f2d506db-fa59-4fe5-ae0e-c3d388a0fb5b"
      },
      "source": [
        "print(classification_report(y_test,model.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.96      0.85        84\n",
            "           1       0.95      0.70      0.81        83\n",
            "\n",
            "    accuracy                           0.83       167\n",
            "   macro avg       0.86      0.83      0.83       167\n",
            "weighted avg       0.86      0.83      0.83       167\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6VpDltTnPgb"
      },
      "source": [
        "**Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyWqlN3Ppend"
      },
      "source": [
        "*RandomizedSearchCV*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gwf3rXNp7g7"
      },
      "source": [
        "def print_results(results):\r\n",
        "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\r\n",
        "\r\n",
        "    means = results.cv_results_['mean_test_score']\r\n",
        "    stds = results.cv_results_['std_test_score']\r\n",
        "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\r\n",
        "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ras1kO3xpgZ0",
        "outputId": "eee4b9f5-2620-4c1d-aa04-6de14be5718d"
      },
      "source": [
        "gbc = GradientBoostingClassifier()\r\n",
        "parameters = {\r\n",
        "    'n_estimators': [5, 50, 100, 150, 250],\r\n",
        "    'max_depth': [2, 3, 4, 8, 16, 32, None],\r\n",
        "    'learning_rate': [0.03, 0.1, 0.3, 1]\r\n",
        "}\r\n",
        "rs = RandomizedSearchCV(gbc, parameters, cv=5,n_iter=20)\r\n",
        "rs.fit(X_train, y_train)\r\n",
        "\r\n",
        "print_results(rs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEST PARAMS: {'n_estimators': 250, 'max_depth': 16, 'learning_rate': 0.03}\n",
            "\n",
            "0.806 (+/-0.055) for {'n_estimators': 250, 'max_depth': 16, 'learning_rate': 0.03}\n",
            "0.786 (+/-0.02) for {'n_estimators': 50, 'max_depth': None, 'learning_rate': 1}\n",
            "0.789 (+/-0.048) for {'n_estimators': 5, 'max_depth': 32, 'learning_rate': 0.03}\n",
            "0.786 (+/-0.076) for {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.1}\n",
            "0.794 (+/-0.051) for {'n_estimators': 150, 'max_depth': None, 'learning_rate': 0.3}\n",
            "0.786 (+/-0.05) for {'n_estimators': 150, 'max_depth': None, 'learning_rate': 0.03}\n",
            "0.702 (+/-0.031) for {'n_estimators': 5, 'max_depth': 4, 'learning_rate': 0.03}\n",
            "0.719 (+/-0.077) for {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.03}\n",
            "0.792 (+/-0.049) for {'n_estimators': 250, 'max_depth': None, 'learning_rate': 0.1}\n",
            "0.711 (+/-0.078) for {'n_estimators': 100, 'max_depth': 2, 'learning_rate': 0.03}\n",
            "0.789 (+/-0.025) for {'n_estimators': 5, 'max_depth': None, 'learning_rate': 0.3}\n",
            "0.788 (+/-0.064) for {'n_estimators': 250, 'max_depth': 32, 'learning_rate': 1}\n",
            "0.803 (+/-0.044) for {'n_estimators': 150, 'max_depth': 16, 'learning_rate': 0.03}\n",
            "0.788 (+/-0.068) for {'n_estimators': 5, 'max_depth': 16, 'learning_rate': 0.03}\n",
            "0.761 (+/-0.058) for {'n_estimators': 50, 'max_depth': 2, 'learning_rate': 0.3}\n",
            "0.785 (+/-0.04) for {'n_estimators': 150, 'max_depth': 16, 'learning_rate': 0.3}\n",
            "0.802 (+/-0.028) for {'n_estimators': 150, 'max_depth': 3, 'learning_rate': 1}\n",
            "0.734 (+/-0.051) for {'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.03}\n",
            "0.792 (+/-0.045) for {'n_estimators': 150, 'max_depth': 32, 'learning_rate': 0.1}\n",
            "0.795 (+/-0.033) for {'n_estimators': 150, 'max_depth': None, 'learning_rate': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA-Rq6JHkLjl"
      },
      "source": [
        "*GridSearchCV*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQbGOJ3ynTWz",
        "outputId": "3d3390c9-a78f-4b47-f46a-064ba76354d4"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\r\n",
        "gbc = GradientBoostingClassifier()\r\n",
        "parameters = {\r\n",
        "    'n_estimators': [80, 90, 100, 125, 150],\r\n",
        "    'max_depth': [2,3,4,5,8,16,None],\r\n",
        "    'learning_rate': [0.03, 0.1, 0.3, 0.5]\r\n",
        "}\r\n",
        "cv = GridSearchCV(gbc, parameters, cv=5)\r\n",
        "cv.fit(X_train, y_train)\r\n",
        "\r\n",
        "print_results(cv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEST PARAMS: {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 80}\n",
            "\n",
            "0.699 (+/-0.045) for {'learning_rate': 0.03, 'max_depth': 2, 'n_estimators': 80}\n",
            "0.707 (+/-0.048) for {'learning_rate': 0.03, 'max_depth': 2, 'n_estimators': 90}\n",
            "0.711 (+/-0.078) for {'learning_rate': 0.03, 'max_depth': 2, 'n_estimators': 100}\n",
            "0.717 (+/-0.09) for {'learning_rate': 0.03, 'max_depth': 2, 'n_estimators': 125}\n",
            "0.717 (+/-0.082) for {'learning_rate': 0.03, 'max_depth': 2, 'n_estimators': 150}\n",
            "0.723 (+/-0.077) for {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 80}\n",
            "0.731 (+/-0.065) for {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 90}\n",
            "0.729 (+/-0.065) for {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.738 (+/-0.041) for {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 125}\n",
            "0.744 (+/-0.034) for {'learning_rate': 0.03, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.746 (+/-0.029) for {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 80}\n",
            "0.747 (+/-0.042) for {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 90}\n",
            "0.75 (+/-0.048) for {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 100}\n",
            "0.762 (+/-0.045) for {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 125}\n",
            "0.764 (+/-0.072) for {'learning_rate': 0.03, 'max_depth': 4, 'n_estimators': 150}\n",
            "0.773 (+/-0.076) for {'learning_rate': 0.03, 'max_depth': 5, 'n_estimators': 80}\n",
            "0.773 (+/-0.073) for {'learning_rate': 0.03, 'max_depth': 5, 'n_estimators': 90}\n",
            "0.783 (+/-0.083) for {'learning_rate': 0.03, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.788 (+/-0.086) for {'learning_rate': 0.03, 'max_depth': 5, 'n_estimators': 125}\n",
            "0.795 (+/-0.079) for {'learning_rate': 0.03, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.783 (+/-0.069) for {'learning_rate': 0.03, 'max_depth': 8, 'n_estimators': 80}\n",
            "0.789 (+/-0.059) for {'learning_rate': 0.03, 'max_depth': 8, 'n_estimators': 90}\n",
            "0.788 (+/-0.057) for {'learning_rate': 0.03, 'max_depth': 8, 'n_estimators': 100}\n",
            "0.792 (+/-0.07) for {'learning_rate': 0.03, 'max_depth': 8, 'n_estimators': 125}\n",
            "0.791 (+/-0.088) for {'learning_rate': 0.03, 'max_depth': 8, 'n_estimators': 150}\n",
            "0.797 (+/-0.039) for {'learning_rate': 0.03, 'max_depth': 16, 'n_estimators': 80}\n",
            "0.797 (+/-0.032) for {'learning_rate': 0.03, 'max_depth': 16, 'n_estimators': 90}\n",
            "0.791 (+/-0.035) for {'learning_rate': 0.03, 'max_depth': 16, 'n_estimators': 100}\n",
            "0.802 (+/-0.041) for {'learning_rate': 0.03, 'max_depth': 16, 'n_estimators': 125}\n",
            "0.802 (+/-0.046) for {'learning_rate': 0.03, 'max_depth': 16, 'n_estimators': 150}\n",
            "0.792 (+/-0.031) for {'learning_rate': 0.03, 'max_depth': 32, 'n_estimators': 80}\n",
            "0.791 (+/-0.044) for {'learning_rate': 0.03, 'max_depth': 32, 'n_estimators': 90}\n",
            "0.791 (+/-0.035) for {'learning_rate': 0.03, 'max_depth': 32, 'n_estimators': 100}\n",
            "0.786 (+/-0.04) for {'learning_rate': 0.03, 'max_depth': 32, 'n_estimators': 125}\n",
            "0.786 (+/-0.045) for {'learning_rate': 0.03, 'max_depth': 32, 'n_estimators': 150}\n",
            "0.789 (+/-0.044) for {'learning_rate': 0.03, 'max_depth': None, 'n_estimators': 80}\n",
            "0.788 (+/-0.032) for {'learning_rate': 0.03, 'max_depth': None, 'n_estimators': 90}\n",
            "0.78 (+/-0.026) for {'learning_rate': 0.03, 'max_depth': None, 'n_estimators': 100}\n",
            "0.794 (+/-0.024) for {'learning_rate': 0.03, 'max_depth': None, 'n_estimators': 125}\n",
            "0.794 (+/-0.029) for {'learning_rate': 0.03, 'max_depth': None, 'n_estimators': 150}\n",
            "0.729 (+/-0.072) for {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 80}\n",
            "0.74 (+/-0.074) for {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 90}\n",
            "0.735 (+/-0.079) for {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100}\n",
            "0.744 (+/-0.078) for {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 125}\n",
            "0.747 (+/-0.086) for {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150}\n",
            "0.761 (+/-0.078) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 80}\n",
            "0.768 (+/-0.075) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 90}\n",
            "0.77 (+/-0.083) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.782 (+/-0.077) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 125}\n",
            "0.792 (+/-0.063) for {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.776 (+/-0.067) for {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 80}\n",
            "0.782 (+/-0.077) for {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 90}\n",
            "0.792 (+/-0.068) for {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
            "0.798 (+/-0.058) for {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 125}\n",
            "0.798 (+/-0.055) for {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 150}\n",
            "0.795 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 80}\n",
            "0.808 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 90}\n",
            "0.791 (+/-0.067) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.802 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 125}\n",
            "0.798 (+/-0.065) for {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.794 (+/-0.063) for {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 80}\n",
            "0.798 (+/-0.058) for {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 90}\n",
            "0.803 (+/-0.06) for {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 100}\n",
            "0.811 (+/-0.052) for {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 125}\n",
            "0.814 (+/-0.052) for {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 150}\n",
            "0.802 (+/-0.024) for {'learning_rate': 0.1, 'max_depth': 16, 'n_estimators': 80}\n",
            "0.797 (+/-0.051) for {'learning_rate': 0.1, 'max_depth': 16, 'n_estimators': 90}\n",
            "0.797 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 16, 'n_estimators': 100}\n",
            "0.791 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 16, 'n_estimators': 125}\n",
            "0.8 (+/-0.036) for {'learning_rate': 0.1, 'max_depth': 16, 'n_estimators': 150}\n",
            "0.789 (+/-0.037) for {'learning_rate': 0.1, 'max_depth': 32, 'n_estimators': 80}\n",
            "0.788 (+/-0.053) for {'learning_rate': 0.1, 'max_depth': 32, 'n_estimators': 90}\n",
            "0.789 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 32, 'n_estimators': 100}\n",
            "0.788 (+/-0.044) for {'learning_rate': 0.1, 'max_depth': 32, 'n_estimators': 125}\n",
            "0.792 (+/-0.023) for {'learning_rate': 0.1, 'max_depth': 32, 'n_estimators': 150}\n",
            "0.791 (+/-0.053) for {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 80}\n",
            "0.783 (+/-0.05) for {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 90}\n",
            "0.783 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 100}\n",
            "0.788 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 125}\n",
            "0.791 (+/-0.02) for {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 150}\n",
            "0.765 (+/-0.069) for {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 80}\n",
            "0.767 (+/-0.099) for {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 90}\n",
            "0.764 (+/-0.083) for {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 100}\n",
            "0.776 (+/-0.102) for {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 125}\n",
            "0.786 (+/-0.08) for {'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 150}\n",
            "0.792 (+/-0.028) for {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 80}\n",
            "0.797 (+/-0.021) for {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 90}\n",
            "0.798 (+/-0.029) for {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.805 (+/-0.013) for {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 125}\n",
            "0.802 (+/-0.031) for {'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.82 (+/-0.063) for {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 80}\n",
            "0.811 (+/-0.049) for {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 90}\n",
            "0.805 (+/-0.077) for {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 100}\n",
            "0.82 (+/-0.041) for {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 125}\n",
            "0.817 (+/-0.048) for {'learning_rate': 0.3, 'max_depth': 4, 'n_estimators': 150}\n",
            "0.805 (+/-0.094) for {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 80}\n",
            "0.808 (+/-0.061) for {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 90}\n",
            "0.802 (+/-0.093) for {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.808 (+/-0.087) for {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 125}\n",
            "0.806 (+/-0.065) for {'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.8 (+/-0.059) for {'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 80}\n",
            "0.818 (+/-0.064) for {'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 90}\n",
            "0.805 (+/-0.053) for {'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 100}\n",
            "0.802 (+/-0.058) for {'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 125}\n",
            "0.794 (+/-0.065) for {'learning_rate': 0.3, 'max_depth': 8, 'n_estimators': 150}\n",
            "0.797 (+/-0.059) for {'learning_rate': 0.3, 'max_depth': 16, 'n_estimators': 80}\n",
            "0.805 (+/-0.065) for {'learning_rate': 0.3, 'max_depth': 16, 'n_estimators': 90}\n",
            "0.803 (+/-0.053) for {'learning_rate': 0.3, 'max_depth': 16, 'n_estimators': 100}\n",
            "0.777 (+/-0.043) for {'learning_rate': 0.3, 'max_depth': 16, 'n_estimators': 125}\n",
            "0.8 (+/-0.046) for {'learning_rate': 0.3, 'max_depth': 16, 'n_estimators': 150}\n",
            "0.792 (+/-0.023) for {'learning_rate': 0.3, 'max_depth': 32, 'n_estimators': 80}\n",
            "0.794 (+/-0.007) for {'learning_rate': 0.3, 'max_depth': 32, 'n_estimators': 90}\n",
            "0.794 (+/-0.028) for {'learning_rate': 0.3, 'max_depth': 32, 'n_estimators': 100}\n",
            "0.786 (+/-0.023) for {'learning_rate': 0.3, 'max_depth': 32, 'n_estimators': 125}\n",
            "0.789 (+/-0.043) for {'learning_rate': 0.3, 'max_depth': 32, 'n_estimators': 150}\n",
            "0.783 (+/-0.064) for {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 80}\n",
            "0.791 (+/-0.032) for {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 90}\n",
            "0.792 (+/-0.015) for {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 100}\n",
            "0.797 (+/-0.029) for {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 125}\n",
            "0.797 (+/-0.048) for {'learning_rate': 0.3, 'max_depth': None, 'n_estimators': 150}\n",
            "0.792 (+/-0.067) for {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 80}\n",
            "0.782 (+/-0.059) for {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 90}\n",
            "0.797 (+/-0.058) for {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 100}\n",
            "0.805 (+/-0.058) for {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 125}\n",
            "0.802 (+/-0.053) for {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 150}\n",
            "0.805 (+/-0.065) for {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 80}\n",
            "0.803 (+/-0.057) for {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 90}\n",
            "0.797 (+/-0.037) for {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 100}\n",
            "0.8 (+/-0.04) for {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 125}\n",
            "0.798 (+/-0.073) for {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 150}\n",
            "0.792 (+/-0.072) for {'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 80}\n",
            "0.797 (+/-0.089) for {'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 90}\n",
            "0.8 (+/-0.09) for {'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 100}\n",
            "0.806 (+/-0.08) for {'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 125}\n",
            "0.803 (+/-0.076) for {'learning_rate': 0.5, 'max_depth': 4, 'n_estimators': 150}\n",
            "0.798 (+/-0.069) for {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 80}\n",
            "0.791 (+/-0.078) for {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 90}\n",
            "0.794 (+/-0.085) for {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 100}\n",
            "0.806 (+/-0.071) for {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 125}\n",
            "0.805 (+/-0.065) for {'learning_rate': 0.5, 'max_depth': 5, 'n_estimators': 150}\n",
            "0.814 (+/-0.065) for {'learning_rate': 0.5, 'max_depth': 8, 'n_estimators': 80}\n",
            "0.812 (+/-0.098) for {'learning_rate': 0.5, 'max_depth': 8, 'n_estimators': 90}\n",
            "0.802 (+/-0.044) for {'learning_rate': 0.5, 'max_depth': 8, 'n_estimators': 100}\n",
            "0.806 (+/-0.083) for {'learning_rate': 0.5, 'max_depth': 8, 'n_estimators': 125}\n",
            "0.792 (+/-0.083) for {'learning_rate': 0.5, 'max_depth': 8, 'n_estimators': 150}\n",
            "0.798 (+/-0.057) for {'learning_rate': 0.5, 'max_depth': 16, 'n_estimators': 80}\n",
            "0.791 (+/-0.047) for {'learning_rate': 0.5, 'max_depth': 16, 'n_estimators': 90}\n",
            "0.78 (+/-0.039) for {'learning_rate': 0.5, 'max_depth': 16, 'n_estimators': 100}\n",
            "0.777 (+/-0.049) for {'learning_rate': 0.5, 'max_depth': 16, 'n_estimators': 125}\n",
            "0.788 (+/-0.037) for {'learning_rate': 0.5, 'max_depth': 16, 'n_estimators': 150}\n",
            "0.792 (+/-0.023) for {'learning_rate': 0.5, 'max_depth': 32, 'n_estimators': 80}\n",
            "0.786 (+/-0.064) for {'learning_rate': 0.5, 'max_depth': 32, 'n_estimators': 90}\n",
            "0.78 (+/-0.042) for {'learning_rate': 0.5, 'max_depth': 32, 'n_estimators': 100}\n",
            "0.786 (+/-0.051) for {'learning_rate': 0.5, 'max_depth': 32, 'n_estimators': 125}\n",
            "0.789 (+/-0.032) for {'learning_rate': 0.5, 'max_depth': 32, 'n_estimators': 150}\n",
            "0.791 (+/-0.041) for {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 80}\n",
            "0.783 (+/-0.054) for {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 90}\n",
            "0.789 (+/-0.037) for {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 100}\n",
            "0.78 (+/-0.044) for {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 125}\n",
            "0.776 (+/-0.044) for {'learning_rate': 0.5, 'max_depth': None, 'n_estimators': 150}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJBpremxcpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751f16da-0be2-4cdc-d23e-1bed4436d2d1"
      },
      "source": [
        "cv.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.819548872180451"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 335
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QOG4XLtxsQC",
        "outputId": "285e1cee-96ed-4cc9-ee30-1cffa7f2e114"
      },
      "source": [
        "print(cv.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
            "                           learning_rate=0.3, loss='deviance', max_depth=4,\n",
            "                           max_features=None, max_leaf_nodes=None,\n",
            "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                           min_samples_leaf=1, min_samples_split=2,\n",
            "                           min_weight_fraction_leaf=0.0, n_estimators=80,\n",
            "                           n_iter_no_change=None, presort='deprecated',\n",
            "                           random_state=None, subsample=1.0, tol=0.0001,\n",
            "                           validation_fraction=0.1, verbose=0,\n",
            "                           warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl1ULu7p03dy",
        "outputId": "8f2fd56e-d921-443d-8f5f-6423a87852a3"
      },
      "source": [
        "cv.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.819548872180451"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7_zgvz64OHD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}